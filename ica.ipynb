{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import LinearSVR\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "\n",
    "from hyperopt import fmin, tpe, hp\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR optimization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_optimization_svr(X, y, cv=6, max_iter_svr=100, max_iter_opt=15):\n",
    "    svr_opt = BayesianOptimization(\n",
    "        lambda epsilon: cross_val_score(\n",
    "            LinearSVR(C=100, epsilon=epsilon, max_iter=max_iter_svr),\n",
    "            X, y.squeeze(), cv=KFold(n_splits=cv).split(X), scoring='neg_mean_squared_error'\n",
    "        ).mean(),\n",
    "        {'epsilon': (0.0, 5.0)},\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    svr_opt.init(10)\n",
    "    svr_opt.maximize(n_iter=max_iter_opt)\n",
    "    \n",
    "    return svr_opt.res['max']['max_params']['epsilon']\n",
    "\n",
    "def hyperopt_optimization_svr(X, y, cv=6, max_iter_svr=100, max_iter_opt=15):\n",
    "    space = hp.choice('regressor_type', [\n",
    "        {\n",
    "            'type': 'svr',\n",
    "            'epsilon': hp.uniform('svr_epsilon', 0.0, 5.0)\n",
    "        }\n",
    "    ])\n",
    "\n",
    "    best = fmin(\n",
    "        fn=lambda args: cross_val_score(\n",
    "            LinearSVR(C=100, epsilon=args['epsilon'], max_iter=max_iter_svr),\n",
    "            X, y.squeeze(), cv=KFold(n_splits=cv).split(X), scoring='neg_mean_squared_error'\n",
    "        ).mean(),\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=max_iter_opt\n",
    "    )\n",
    "\n",
    "    return best['svr_epsilon']\n",
    "\n",
    "def evaulate_best_svr_argument(X, y, eps_vals: list, cv=6):\n",
    "    scores = []\n",
    "    for e in eps_vals:\n",
    "        scores.append(cross_val_score(\n",
    "            LinearSVR(C=100, epsilon=e, max_iter=200),\n",
    "            X, y.squeeze(), cv=KFold(n_splits=cv).split(X), scoring='neg_mean_squared_error'\n",
    "        ).mean())\n",
    "        \n",
    "    return eps_vals[np.argmax(scores)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF regressor optimization code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperopt for lightgbm shows terrible results\n",
    "def hyperopt_optimization_lightgbm(X, y, cv=6, max_iter_opt=15):\n",
    "    space = hp.choice('regressor_type', [\n",
    "        {\n",
    "            'type': 'lightgbm',\n",
    "            'feature_fraction': hp.uniform('feature_fraction', 0.05, 0.95),\n",
    "            'bagging_fraction': hp.uniform('bagging_fraction', 0.05, 0.95),\n",
    "            'bagging_freq': hp.uniform('bagging_freq', 1, 50),\n",
    "            'n_estimators': hp.uniform('n_estimators', 5, 50),\n",
    "            #'max_bin': hp.uniform('max_bin', )\n",
    "        }\n",
    "    ])\n",
    "\n",
    "    best = fmin(\n",
    "        fn=lambda args: cross_val_score(\n",
    "            LGBMRegressor(\n",
    "                boosting_type='rf', \n",
    "                feature_fraction=args['feature_fraction'], \n",
    "                bagging_freq=int(args['bagging_freq']), \n",
    "                bagging_fraction=args['bagging_fraction'],\n",
    "                n_estimators=int(args['n_estimators'])\n",
    "            ),\n",
    "            X, y.squeeze(), cv=KFold(n_splits=cv).split(X), scoring='neg_mean_squared_error'\n",
    "        ).mean(),\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=max_iter_opt\n",
    "    )\n",
    "    \n",
    "    return best\n",
    "\n",
    "def bayesian_optimization_lightgbm(X, y, cv=6, max_iter_opt=15):\n",
    "    svr_opt = BayesianOptimization(\n",
    "        lambda feature_fraction, bagging_freq, bagging_fraction, n_estimators: cross_val_score(\n",
    "            LGBMRegressor(\n",
    "                boosting_type='rf', \n",
    "                feature_fraction=feature_fraction, \n",
    "                bagging_freq=int(bagging_freq), \n",
    "                bagging_fraction=bagging_fraction,\n",
    "                n_estimators=int(n_estimators)\n",
    "            ),\n",
    "            X, y.squeeze(), cv=KFold(n_splits=cv).split(X), scoring='neg_mean_squared_error'\n",
    "        ).mean(),\n",
    "        {'feature_fraction': (0.05, 0.95),\n",
    "         'bagging_fraction': (0.05, 0.95),\n",
    "         'bagging_freq': (1, 50),\n",
    "         'n_estimators': (5, 50) },\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    svr_opt.init(10)\n",
    "    svr_opt.maximize(n_iter=max_iter_opt)\n",
    "    \n",
    "    return svr_opt.res['max']['max_params']#['C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facebook Comment Volume Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/facebook_comments.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: (40949, 54)\n"
     ]
    }
   ],
   "source": [
    "print('dataset size: {}'.format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding categorical variables\n",
    "# H Local - category\n",
    "# Post Promotion Status - category\n",
    "# Base Time - time variable\n",
    "# Page Category - category\n",
    "\n",
    "H_Local = OneHotEncoder().fit_transform(df['H Local'].values.reshape(-1, 1)).todense()\n",
    "Post_Promotion_Status = OneHotEncoder().fit_transform(df['Post Promotion Status'].values.reshape(-1, 1)).todense()\n",
    "Base_Time = OneHotEncoder().fit_transform(df['Base Time'].values.reshape(-1, 1)).todense()\n",
    "Page_Category = OneHotEncoder().fit_transform(df['Page Category'].values.reshape(-1, 1)).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.Target.values.reshape(-1, 1)\n",
    "X = df.drop(['H Local', 'Post Promotion Status', 'Base Time', 'Page Category', 'Target'], axis=1).values\n",
    "X = np.hstack([X, H_Local, Post_Promotion_Status, Base_Time, Page_Category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size after preprocessing: (40949, 228)\n"
     ]
    }
   ],
   "source": [
    "print('dataset size after preprocessing: {}'.format(X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model with ICA-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of components is fixed to 10\n",
    "ica = FastICA(n_components=10)\n",
    "X_ica = ica.fit_transform(X_train)\n",
    "X_val_ica = ica.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ica, y_train = shuffle(X_ica, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Estimating SVR penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-3.6177188]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.14115973]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-9.50210452]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 2, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-26.20570505]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.47874683]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([10.38487732]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([1.00382406]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 61, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    }
   ],
   "source": [
    "eps_hyperopt = hyperopt_optimization_svr(X_ica, y_train, cv=4, max_iter_svr=200, max_iter_opt=15)\n",
    "eps_bayesian = bayesian_optimization_svr(X_ica, y_train, cv=4, max_iter_svr=200, max_iter_opt=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_opt = evaulate_best_svr_argument(X_ica, y_train, [eps_hyperopt, eps_bayesian], cv=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Estimating LightGBM params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.42612155]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 49, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-1.62693076]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 48, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-1.55897449]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-1.40316226]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([3.7844682]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 48, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    }
   ],
   "source": [
    "params_opt = bayesian_optimization_lightgbm(X_train, y_train, cv=6, max_iter_opt=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_opt['bagging_freq'] = int(params_opt['bagging_freq'])\n",
    "params_opt['n_estimators'] = int(params_opt['n_estimators'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Evaluate with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'linear': LinearRegression(),\n",
    "    'svr': LinearSVR(C=100, epsilon=eps_opt, max_iter=200),\n",
    "    'forest': LGBMRegressor(boosting_type='rf', **params_opt)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {}\n",
    "\n",
    "for k, model in models.items():\n",
    "    stats[k] = []\n",
    "    kfold = KFold(n_splits=8, shuffle=True)\n",
    "    \n",
    "    for train_ix, test_ix in kfold.split(X_ica, y_train):\n",
    "        X_crossval_train, X_crossval_test = X_ica[train_ix], X_ica[test_ix]\n",
    "        y_crossval_train, y_crossval_test = y_train[train_ix], y_train[test_ix]\n",
    "        \n",
    "        # here must be sume sort of optimization\n",
    "        model.fit(X_crossval_train, y_crossval_train.ravel())\n",
    "        stats[k].append(mean_squared_error(model.predict(X_crossval_test), y_crossval_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for decorrelated data using ICA (averate scores)\n",
      "linear, MSE: 979.0974515809114\n",
      "svr, MSE: 1078.214427530016\n",
      "forest, MSE: 1301.8619306696535\n"
     ]
    }
   ],
   "source": [
    "print('for decorrelated data using ICA (averate scores)')\n",
    "for model, model_stats in stats.items():\n",
    "    print('{}, MSE: {}'.format(model, np.mean(model_stats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for decorrelated data using ICA (validation scores):\n",
      "linear, MSE: 886.4990818365944\n",
      "svr, MSE: 1107.2444114939578\n",
      "forest, MSE: 1417.8398046398047\n"
     ]
    }
   ],
   "source": [
    "print('for decorrelated data using ICA (validation scores):')\n",
    "for name, model in models.items():\n",
    "    model.fit(X_ica, y_train.squeeze())\n",
    "    print('{}, MSE: {}'.format(name, mean_squared_error(model.predict(X_val_ica), y_val.squeeze())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parkinsons Telemonitoring Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/parkinsons_updrs.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: (5875, 22)\n"
     ]
    }
   ],
   "source": [
    "print('dataset size: {}'.format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = df['subject#'].unique().tolist()\n",
    "subject_binary = np.zeros((df.shape[0], len(subject)))\n",
    "for k, i in df.iterrows():\n",
    "    subject_binary[k, int(i['subject#']) - 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing categorical features with binary values\n",
    "y = df.total_UPDRS.values\n",
    "X = df.drop(['motor_UPDRS', 'total_UPDRS', 'subject#'], axis=1).values\n",
    "X = np.concatenate([subject_binary, X], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size after preprocessing: (5875, 61)\n"
     ]
    }
   ],
   "source": [
    "print('dataset size after preprocessing: {}'.format(X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model with ICA-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of components is fixed to 10\n",
    "ica = FastICA(n_components=10)\n",
    "X_ica = ica.fit_transform(X_train)\n",
    "X_val_ica = ica.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ica, y_train = shuffle(X_ica, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Estimating SVR penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0097045]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.01129719]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00829343]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.06897306]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 8, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.14559271]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    }
   ],
   "source": [
    "eps_hyperopt = hyperopt_optimization_svr(X_ica, y_train, cv=4, max_iter_svr=200, max_iter_opt=15)\n",
    "eps_bayesian = bayesian_optimization_svr(X_ica, y_train, cv=4, max_iter_svr=200, max_iter_opt=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_opt = evaulate_best_svr_argument(X_ica, y_train, [eps_hyperopt, eps_bayesian], cv=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Estimating LightGBM params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.0016018]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 2, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "D:\\Program Files (x86)\\Anaconda\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-3.12001425e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 2, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    }
   ],
   "source": [
    "params_opt = bayesian_optimization_lightgbm(X_train, y_train, cv=6, max_iter_opt=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_opt['bagging_freq'] = int(params_opt['bagging_freq'])\n",
    "params_opt['n_estimators'] = int(params_opt['n_estimators'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Evaluate with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'linear': LinearRegression(),\n",
    "    'svr': LinearSVR(C=100, epsilon=eps_opt, max_iter=200),\n",
    "    'forest': LGBMRegressor(boosting_type='rf', **params_opt)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {}\n",
    "\n",
    "for k, model in models.items():\n",
    "    stats[k] = []\n",
    "    kfold = KFold(n_splits=8, shuffle=True)\n",
    "    \n",
    "    for train_ix, test_ix in kfold.split(X_ica, y_train):\n",
    "        X_crossval_train, X_crossval_test = X_ica[train_ix], X_ica[test_ix]\n",
    "        y_crossval_train, y_crossval_test = y_train[train_ix], y_train[test_ix]\n",
    "        \n",
    "        # here must be sume sort of optimization\n",
    "        model.fit(X_crossval_train, y_crossval_train.ravel())\n",
    "        stats[k].append(mean_squared_error(model.predict(X_crossval_test), y_crossval_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for decorrelated data using ICA\n",
      "linear, MSE: 81.75051216352603\n",
      "svr, MSE: 82.46107464397488\n",
      "forest, MSE: 956.0731875133065\n"
     ]
    }
   ],
   "source": [
    "print('for decorrelated data using ICA')\n",
    "for model, model_stats in stats.items():\n",
    "    print('{}, MSE: {}'.format(model, np.mean(model_stats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for decorrelated data using ICA (validation scores):\n",
      "linear, MSE: 85.0417709422462\n",
      "svr, MSE: 85.71758733269266\n",
      "forest, MSE: 961.1154826647958\n"
     ]
    }
   ],
   "source": [
    "print('for decorrelated data using ICA (validation scores):')\n",
    "for name, model in models.items():\n",
    "    model.fit(X_ica, y_train.squeeze())\n",
    "    print('{}, MSE: {}'.format(name, mean_squared_error(model.predict(X_val_ica), y_val.squeeze())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy efficiency Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./datasets/ENB2012_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: (768, 10)\n"
     ]
    }
   ],
   "source": [
    "print('dataset size: {}'.format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = df['X6'].unique().tolist()\n",
    "subject_map = dict(zip(subject, range(len(subject))))\n",
    "subject_binary = np.zeros((df.shape[0], len(subject)))\n",
    "for k, i in df.iterrows():\n",
    "    subject_binary[k, subject_map[i['X6']]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing categorical features with binary values\n",
    "y = df.Y1.values\n",
    "X = df.drop(['Y1', 'Y2', 'X6'], axis=1).values\n",
    "X = np.concatenate([subject_binary, X], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size after preprocessing: (768, 11)\n"
     ]
    }
   ],
   "source": [
    "print('dataset size after preprocessing: {}'.format(X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model with ICA-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of components is fixed to 5\n",
    "ica = FastICA(n_components=5)\n",
    "X_ica = ica.fit_transform(X_train)\n",
    "X_val_ica = ica.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ica, y_train = shuffle(X_ica, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Estimating SVR penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_hyperopt = hyperopt_optimization_svr(X_ica, y_train, cv=4, max_iter_svr=200, max_iter_opt=15)\n",
    "eps_bayesian = bayesian_optimization_svr(X_ica, y_train, cv=4, max_iter_svr=200, max_iter_opt=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_opt = evaulate_best_svr_argument(X_ica, y_train, [eps_hyperopt, eps_bayesian], cv=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Estimating LightGBM params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_opt = bayesian_optimization_lightgbm(X_train, y_train, cv=6, max_iter_opt=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_opt['bagging_freq'] = int(params_opt['bagging_freq'])\n",
    "params_opt['n_estimators'] = int(params_opt['n_estimators'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Evaluate with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'linear': LinearRegression(),\n",
    "    'svr': LinearSVR(C=100, epsilon=eps_opt, max_iter=200),\n",
    "    'forest': LGBMRegressor(boosting_type='rf', **params_opt)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {}\n",
    "\n",
    "for k, model in models.items():\n",
    "    stats[k] = []\n",
    "    kfold = KFold(n_splits=8, shuffle=True)\n",
    "    \n",
    "    for train_ix, test_ix in kfold.split(X_ica, y_train):\n",
    "        X_crossval_train, X_crossval_test = X_ica[train_ix], X_ica[test_ix]\n",
    "        y_crossval_train, y_crossval_test = y_train[train_ix], y_train[test_ix]\n",
    "        \n",
    "        # here must be sume sort of optimization\n",
    "        model.fit(X_crossval_train, y_crossval_train.ravel())\n",
    "        stats[k].append(mean_squared_error(model.predict(X_crossval_test), y_crossval_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for decorrelated data using ICA\n",
      "linear, MSE: 21.519151782115316\n",
      "svr, MSE: 21.998777446472516\n",
      "forest, MSE: 598.1371824865678\n"
     ]
    }
   ],
   "source": [
    "print('for decorrelated data using ICA')\n",
    "for model, model_stats in stats.items():\n",
    "    print('{}, MSE: {}'.format(model, np.mean(model_stats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for decorrelated data using ICA (validation scores):\n",
      "linear, MSE: 116.15323392774\n",
      "svr, MSE: 172.61538442556483\n",
      "forest, MSE: 118.17767193979121\n"
     ]
    }
   ],
   "source": [
    "print('for decorrelated data using ICA (validation scores):')\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train.squeeze())\n",
    "    print('{}, MSE: {}'.format(name, mean_squared_error(model.predict(X_val), y_val.squeeze())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
