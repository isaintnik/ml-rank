{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import struct\n",
    "from importlib import reload\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from lightgbm import LGBMClassifier \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "\n",
    "from hyperopt import fmin, tpe, hp\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from scipy.stats import entropy\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy as copy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrank.dichtomization as dichtomization\n",
    "import mlrank.orthogonalization as orthogonalization\n",
    "import mlrank.hyperparams_opt as hyperparams_opt\n",
    "\n",
    "reload(dichtomization)\n",
    "reload(orthogonalization)\n",
    "reload(hyperparams_opt)\n",
    "\n",
    "MaxentropyMedianDichtomizationTransformer = dichtomization.MaxentropyMedianDichtomizationTransformer\n",
    "MLRankTransformer = orthogonalization.MLRankTransformer\n",
    "MLRankTargetBasedTransformer = orthogonalization.MLRankTargetBasedTransformer\n",
    "bayesian_optimization_lightgbm = hyperparams_opt.bayesian_optimization_lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../datasets/cancer/breast_cancer.csv')\n",
    "y = df.diagnosis.replace('M', 0).replace('B', 1).values\n",
    "X = np.asarray(df.drop(['diagnosis', 'id', 'Unnamed: 32'], axis=1).as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    #'rf': LGBMClassifier(boosting_type='rf', **params_opt),\n",
    "    'lr': LogisticRegression(random_state=42, multi_class='ovr', solver='liblinear', C=10000, tol=1e-2),\n",
    "    'svc': LinearSVC(multi_class='ovr', C=10000, tol=1e-6, random_state=42),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = MLRankTransformer(models['lr'], exhausitve=True, verbose=1)\n",
    "# используем SVC, так как LR не сходится по энтропии к таргету на данном датасете\n",
    "transform_target_min_xor = MLRankTargetBasedTransformer(models['svc'], verbose=1, use_xor=True, use_max_entropy=False)\n",
    "transform_target_max_xor = MLRankTargetBasedTransformer(models['svc'], verbose=1, use_xor=True, use_max_entropy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing starting feature 0\n",
      "processing starting feature 1\n",
      "processing starting feature 2\n",
      "processing starting feature 3\n",
      "processing starting feature 4\n",
      "processing starting feature 5\n",
      "processing starting feature 6\n",
      "processing starting feature 7\n",
      "processing starting feature 8\n",
      "processing starting feature 9\n",
      "processing starting feature 10\n",
      "processing starting feature 11\n",
      "processing starting feature 12\n",
      "processing starting feature 13\n",
      "processing starting feature 14\n",
      "processing starting feature 15\n",
      "processing starting feature 16\n",
      "processing starting feature 17\n",
      "processing starting feature 18\n",
      "processing starting feature 19\n",
      "processing starting feature 20\n",
      "processing starting feature 21\n",
      "processing starting feature 22\n",
      "processing starting feature 23\n",
      "processing starting feature 24\n",
      "processing starting feature 25\n",
      "processing starting feature 26\n",
      "processing starting feature 27\n",
      "processing starting feature 28\n",
      "processing starting feature 29\n"
     ]
    }
   ],
   "source": [
    "features, indices = transform.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_target_min_equi, indices_target_min_equi = transform_target_min_equi.fit_transform(X, y.reshape(-1, 1))\n",
    "features_target_max_xor, indices_target_max_xor = transform_target_max_xor.fit_transform(X, y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_target_min_xor, indices_target_min_xor = transform_target_min_xor.fit_transform(X, y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 3, 0, 1, 2, 4]\n",
      "[9, 15, 0, 1]\n",
      "[23, 3, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(indices_target_min_equi) # пересечение с истинным оптимальным ('6', '20', '21', '27', '28')\n",
    "print(indices_target_max_xor) # пересечение с истинным оптимальным и с ранжированными коэффициентыми логистической регрессии [2, 22, 21, 13, 20]\n",
    "print(indices_target_min_xor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Считаем точность на оптимальном сабсете, полученном из таргета (min, <\\-\\>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9126912280701756\n",
      "0.9575508771929826\n"
     ]
    }
   ],
   "source": [
    "accur_score = list()\n",
    "\n",
    "for i in range(1000):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X[:, indices_target_min_equi], y, test_size=0.5)#, random_state=1)\n",
    "    \n",
    "    record = dict()\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train.squeeze())\n",
    "        record[name] = accuracy_score(model.predict(X_val), y_val.squeeze())\n",
    "    accur_score.append(record)\n",
    "\n",
    "print(np.mean([i['svc'] for i in accur_score]))\n",
    "print(np.mean([i['lr'] for i in accur_score]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is ready\n",
      "svc is ready\n"
     ]
    }
   ],
   "source": [
    "stats = {}\n",
    "\n",
    "for k, model in models.items():\n",
    "    stats[k] = []\n",
    "    kfold = KFold(n_splits=32, shuffle=True)\n",
    "    \n",
    "    for train_ix, test_ix in kfold.split(X_train, y_train):\n",
    "        X_crossval_train, X_crossval_test = X_train[train_ix], X_train[test_ix]\n",
    "        y_crossval_train, y_crossval_test = y_train[train_ix], y_train[test_ix]\n",
    "        \n",
    "        # here must be sume sort of optimization\n",
    "        model.fit(X_crossval_train, y_crossval_train.ravel())\n",
    "        stats[k].append(accuracy_score(model.predict(X_crossval_test), y_crossval_test, normalize=True))\n",
    "    print(k + ' is ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for pure data (averate scores):\n",
      "lr, Accuracy: 0.96484375\n",
      "svc, Accuracy: 0.8927951388888888\n"
     ]
    }
   ],
   "source": [
    "print('for pure data (averate scores):')\n",
    "for model, model_stats in stats.items():\n",
    "    print('{}, Accuracy: {}'.format(model, np.mean(model_stats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for pure data (validation scores):\n",
      "pure: lr, Accuracy: 0.9543859649122807\n",
      "pure: svc, Accuracy: 0.9438596491228071\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "print('for pure data (validation scores):')\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train.squeeze())\n",
    "    print('pure: {}, Accuracy: {}'.format(name, accuracy_score(model.predict(X_val), y_val.squeeze())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ортогонализуем специально под SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_transform = MLRankTransformer(models['svc'], exhausitve=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_min_equi, _  = optimal_transform.fit_transform(\n",
    "    np.hstack([X[:, i].reshape(-1, 1) for i in indices_target_min_equi])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(features_min_equi, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is ready\n",
      "svc is ready\n"
     ]
    }
   ],
   "source": [
    "stats = {}\n",
    "\n",
    "for k, model in models.items():\n",
    "    stats[k] = []\n",
    "    kfold = KFold(n_splits=32, shuffle=True)\n",
    "    \n",
    "    for train_ix, test_ix in kfold.split(X_train, y_train):\n",
    "        X_crossval_train, X_crossval_test = X_train[train_ix], X_train[test_ix]\n",
    "        y_crossval_train, y_crossval_test = y_train[train_ix], y_train[test_ix]\n",
    "        \n",
    "        # here must be sume sort of optimization\n",
    "        model.fit(X_crossval_train, y_crossval_train.ravel())\n",
    "        stats[k].append(accuracy_score(model.predict(X_crossval_test), y_crossval_test, normalize=True))\n",
    "    print(k + ' is ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for pure data (averate scores):\n",
      "lr, Accuracy: 0.865234375\n",
      "svc, Accuracy: 0.8359375\n"
     ]
    }
   ],
   "source": [
    "print('for pure data (averate scores):')\n",
    "for model, model_stats in stats.items():\n",
    "    print('{}, Accuracy: {}'.format(model, np.mean(model_stats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for pure data (validation scores):\n",
      "pure: lr, Accuracy: 0.8771929824561403\n",
      "pure: svc, Accuracy: 0.8771929824561403\n"
     ]
    }
   ],
   "source": [
    "print('for pure data (validation scores):')\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train.squeeze())\n",
    "    print('pure: {}, Accuracy: {}'.format(name, accuracy_score(model.predict(X_val), y_val.squeeze())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Считаем точность на оптимальном сабсете, полученном из таргета (max, xor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X[:, indices_target_max_xor], y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is ready\n",
      "svc is ready\n"
     ]
    }
   ],
   "source": [
    "stats = {}\n",
    "\n",
    "for k, model in models.items():\n",
    "    stats[k] = []\n",
    "    kfold = KFold(n_splits=32, shuffle=True)\n",
    "    \n",
    "    for train_ix, test_ix in kfold.split(X_train, y_train):\n",
    "        X_crossval_train, X_crossval_test = X_train[train_ix], X_train[test_ix]\n",
    "        y_crossval_train, y_crossval_test = y_train[train_ix], y_train[test_ix]\n",
    "        \n",
    "        # here must be sume sort of optimization\n",
    "        model.fit(X_crossval_train, y_crossval_train.ravel())\n",
    "        stats[k].append(accuracy_score(model.predict(X_crossval_test), y_crossval_test, normalize=True))\n",
    "    print(k + ' is ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for pure data (averate scores):\n",
      "lr, Accuracy: 0.94140625\n",
      "svc, Accuracy: 0.830078125\n"
     ]
    }
   ],
   "source": [
    "print('for pure data (averate scores):')\n",
    "for model, model_stats in stats.items():\n",
    "    print('{}, Accuracy: {}'.format(model, np.mean(model_stats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for pure data (validation scores):\n",
      "pure: lr, Accuracy: 0.9298245614035088\n",
      "pure: svc, Accuracy: 0.8771929824561403\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "print('for pure data (validation scores):')\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train.squeeze())\n",
    "    print('pure: {}, Accuracy: {}'.format(name, accuracy_score(model.predict(X_val), y_val.squeeze())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ортогонализуем специально под SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_transform = MLRankTransformer(models['svc'], exhausitve=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_max_xor, _  = optimal_transform.fit_transform(\n",
    "    np.hstack([X[:, i].reshape(-1, 1) for i in indices_target_max_xor])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(features_min_equi, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is ready\n",
      "svc is ready\n"
     ]
    }
   ],
   "source": [
    "stats = {}\n",
    "\n",
    "for k, model in models.items():\n",
    "    stats[k] = []\n",
    "    kfold = KFold(n_splits=32, shuffle=True)\n",
    "    \n",
    "    for train_ix, test_ix in kfold.split(X_train, y_train):\n",
    "        X_crossval_train, X_crossval_test = X_train[train_ix], X_train[test_ix]\n",
    "        y_crossval_train, y_crossval_test = y_train[train_ix], y_train[test_ix]\n",
    "        \n",
    "        # here must be sume sort of optimization\n",
    "        model.fit(X_crossval_train, y_crossval_train.ravel())\n",
    "        stats[k].append(accuracy_score(model.predict(X_crossval_test), y_crossval_test, normalize=True))\n",
    "    print(k + ' is ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for pure data (averate scores):\n",
      "lr, Accuracy: 0.865234375\n",
      "svc, Accuracy: 0.8359375\n"
     ]
    }
   ],
   "source": [
    "print('for pure data (averate scores):')\n",
    "for model, model_stats in stats.items():\n",
    "    print('{}, Accuracy: {}'.format(model, np.mean(model_stats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for pure data (validation scores):\n",
      "pure: lr, Accuracy: 0.8771929824561403\n",
      "pure: svc, Accuracy: 0.8771929824561403\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "print('for pure data (validation scores):')\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train.squeeze())\n",
    "    print('pure: {}, Accuracy: {}'.format(name, accuracy_score(model.predict(X_val), y_val.squeeze())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Смотрим важность факторов из оригинального алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ix = np.unique(indices).tolist()\n",
    "ix_counts = {i: 0 for i in unique_ix}\n",
    "\n",
    "for row in indices:\n",
    "    ranks = dict(zip(row.tolist(), reversed(range(row.shape[0]))))\n",
    "    for i, j in ranks.items():\n",
    "        ix_counts[i] += j / (row.shape[0]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25f19fe8d68>"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD/CAYAAAAKVJb/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(ix_counts).sort_values(ascending=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Смотрим на коэффициенты в логистической регрессии (важность факторов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_coefs = []\n",
    "\n",
    "for x_features in features:\n",
    "    c = copy(models['lr'])\n",
    "    c.fit(x_features, y)\n",
    "    \n",
    "    # summing over unique target values (32)\n",
    "    model_coefs.append(np.abs(c.coef_).sum(0))\n",
    "model_coefs = np.array(model_coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_coefs = [model_coefs[:, i*32:(i+1)*32] for i in range(model_coefs.shape[1] // 32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_coefs_sum = [model_coefs[i].sum() for i in range(len(model_coefs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4770.690515856979, 0),\n",
       " (4042.145837308146, 3),\n",
       " (2587.0352020443147, 1),\n",
       " (2562.3329986623203, 2),\n",
       " (1951.2870336485007, 4),\n",
       " (953.3887281526677, 5),\n",
       " (646.7843049228878, 6),\n",
       " (503.72574259078556, 7),\n",
       " (370.9363758652515, 8),\n",
       " (300.24122400194244, 9),\n",
       " (171.20365178733994, 10),\n",
       " (149.48364027050798, 11),\n",
       " (132.47428392049858, 12),\n",
       " (125.43516632237723, 14),\n",
       " (114.66153692510102, 13),\n",
       " (94.95297687409656, 15),\n",
       " (80.70629831875058, 16),\n",
       " (49.87183744041835, 17),\n",
       " (12.265003447414351, 18),\n",
       " (0.0, 19),\n",
       " (0.0, 20),\n",
       " (0.0, 21),\n",
       " (0.0, 22),\n",
       " (0.0, 23),\n",
       " (0.0, 24),\n",
       " (0.0, 25),\n",
       " (0.0, 26),\n",
       " (0.0, 27),\n",
       " (0.0, 28)]"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ну, в принципе, все логично.\n",
    "\n",
    "sorted(zip(model_coefs_sum, range(len(model_coefs_sum))), key=lambda x: -x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
