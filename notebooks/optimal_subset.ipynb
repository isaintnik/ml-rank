{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "from copy import deepcopy as copy\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils import check_array, as_float_array\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector, ExhaustiveFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_holdout_interations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./classification/datasets/cancer/breast_cancer.csv')\n",
    "y = df.diagnosis.replace('M', 0).replace('B', 1).values\n",
    "X = np.asarray(df.drop(['diagnosis', 'id', 'Unnamed: 32'], axis=1).as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'lr': LogisticRegression(random_state=42, multi_class='ovr', solver='liblinear', C=10000, tol=1e-2),\n",
    "    'svc': LinearSVC(multi_class='ovr', C=10000, tol=1e-2, max_iter=250),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SequentialFeatureSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model type: lr\n",
      "model type: svc\n"
     ]
    }
   ],
   "source": [
    "model_feats = dict()\n",
    "\n",
    "for k, v in models.items():\n",
    "    print('model type: {}'.format(k))\n",
    "    sfs = SequentialFeatureSelector(v, k_features=10, scoring='accuracy')\n",
    "    sfs.fit(X, y)\n",
    "    \n",
    "    model_feats[k] = [int(i) for i in sfs.subsets_[5]['feature_names']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': [4, 7, 21, 22, 24], 'svc': [1, 6, 23, 24, 28]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9355438596491229\n",
      "0.9722105263157895\n"
     ]
    }
   ],
   "source": [
    "accur_score = list()\n",
    "\n",
    "for i in range(n_holdout_interations):\n",
    "    record = dict()\n",
    "    for name, model in models.items():\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X[:, model_feats[name]], y, test_size=0.5)#, random_state=1)\n",
    "        \n",
    "        model.fit(X_train, y_train.squeeze())\n",
    "        record[name] = accuracy_score(model.predict(X_val), y_val.squeeze())\n",
    "    accur_score.append(record)\n",
    "\n",
    "print(np.mean([i['svc'] for i in accur_score]))\n",
    "print(np.mean([i['lr'] for i in accur_score]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExhaustiveFeatureSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExhaustiveFeatureSelector(clone_estimator=True, cv=5,\n",
       "             estimator=LogisticRegression(C=10000, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          n_jobs=None, penalty='l2', random_state=42, solver='liblinear',\n",
       "          tol=0.01, verbose=0, warm_start=False),\n",
       "             max_features=5, min_features=1, n_jobs=-1,\n",
       "             pre_dispatch='2*n_jobs', print_progress=False,\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efs = ExhaustiveFeatureSelector(estimator=models['lr'], max_features=5, scoring='accuracy', n_jobs=-1, print_progress=False)\n",
    "efs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('17', '21', '23', '24', '28')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efs.best_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9732280701754387\n"
     ]
    }
   ],
   "source": [
    "accur_score = list()\n",
    "\n",
    "for i in range(n_holdout_interations):\n",
    "    record = dict()\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X[:, [int(i) for i in efs.best_feature_names_]], y, test_size=0.5)#, random_state=1)\n",
    "        \n",
    "    models['lr'].fit(X_train, y_train.squeeze())\n",
    "    record['lr'] = accuracy_score(models['lr'].predict(X_val), y_val.squeeze())\n",
    "    accur_score.append(record)\n",
    "\n",
    "print(np.mean([i['lr'] for i in accur_score]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RecursiveFeatureElimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_feats = dict()\n",
    "\n",
    "for k, v in models.items():\n",
    "    model_feats[k] = [int(i) for i in sfs.subsets_[5]['feature_names']]\n",
    "    rfe = RFE(estimator=v, n_features_to_select=5)\n",
    "    rfe.fit(X, y)\n",
    "    model_feats[k] = np.array(list(range(X.shape[1])))[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': array([10, 20, 21, 23, 27]), 'svc': array([ 0,  6, 13, 19, 23])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9130877192982457\n",
      "0.9646666666666667\n"
     ]
    }
   ],
   "source": [
    "accur_score = list()\n",
    "\n",
    "for i in range(n_holdout_interations):\n",
    "    record = dict()\n",
    "    for name, model in models.items():\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X[:, model_feats[name]], y, test_size=0.5)#, random_state=1)\n",
    "        \n",
    "        model.fit(X_train, y_train.squeeze())\n",
    "        record[name] = accuracy_score(model.predict(X_val), y_val.squeeze())\n",
    "    accur_score.append(record)\n",
    "\n",
    "print(np.mean([i['svc'] for i in accur_score]))\n",
    "print(np.mean([i['lr'] for i in accur_score]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression coefficents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_coefs = []\n",
    "\n",
    "c = copy(models['lr'])\n",
    "c.fit(X, y)\n",
    "    \n",
    "model_coefs = np.abs(c.coef_).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.8956650592717343, 10),\n",
       " (1.7403622083957977, 21),\n",
       " (1.3205567864813075, 20),\n",
       " (1.3197392480935726, 28),\n",
       " (1.2445662612696033, 13)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(model_coefs.tolist(), range(model_coefs.shape[0])), key = lambda x: -x[0])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
